{"cells":[{"cell_type":"markdown","source":["<H1> FedPROX\n"],"metadata":{"id":"3P2niw2YYZNp"}},{"cell_type":"markdown","metadata":{"id":"TSmy5KK8DhTD"},"source":["Connect the Notebook with GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiRQXbhwDcR5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.insert(0, '/content/drive/MyDrive/FL2022/FedPROX')"]},{"cell_type":"markdown","metadata":{"id":"WqI1MfzJEUiE"},"source":["Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nm5WvZ7JDv-h"},"outputs":[],"source":["from options import args_parser\n","from update import LocalUpdate, test_inference, client_update, server_aggregate, test\n","from utils import get_dataset, average_weights, weighted_average_weights, exp_details, get_n_params\n","from modelRN50 import ResNet50\n","import torch\n","torch.cuda.empty_cache()\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm # progress bar\n","import copy\n","from torch.utils.tensorboard import SummaryWriter\n","logger = SummaryWriter('../logs')"]},{"cell_type":"markdown","metadata":{"id":"p4LJZk1LWLyz"},"source":["Set the parameters for the training "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tngUSzAkWLyz"},"outputs":[],"source":["sys.argv=['',\n","          '--iid=0',  #0 -> NONiid, 1 -> iid\n","          '--num_users=100',\n","          '--lr=0.0001',\n","          '--local_ep=5',\n","          '--epochs=10',\n","          '--optimizer=adam',\n","          '--norm=batch_norm',\n","          '--local_bs=10',\n","          '--dataset=cifar',\n","          '--loss=CrossEntropyLoss',\n","          '--gpu=/device:GPU:0']\n","args=args_parser()\n","num_selected = int( args.num_users * args.frac )\n","baseline_num = 100 # number of baseline images to be saved on the global server\n","                   # for retraining of the client's model before aggregation\n","unbalanced = False # if True the clients will contain different number of classes\n","verbose = False\n","mu=0.01\n"]},{"cell_type":"markdown","metadata":{"id":"mt7RSlRbWLyz"},"source":["Set the device on cuda"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","if verbose:\n"," print(f\"Device available: {device}\")"],"metadata":{"id":"aMig_MUPKu7a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZQPaG4clWLyz"},"source":["###Build the Model ResNet-50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RW_ixot4WLyz"},"outputs":[],"source":["global_model = ResNet50(args.norm)\n","global_model.to(device)\n","global_model.train()\n","if verbose:\n","  print(global_model)\n","  print(f\"Number of Parameters: {get_n_params(global_model)}\")\n","\n","global_weights = global_model.state_dict()\n","client_models = [ global_model for _ in range(num_selected)]\n","\n","# Synchronizing the clients with the global model \n","for model in client_models:\n","    model.load_state_dict(global_model.state_dict()) \n","# Optimizer selection\n","if args.optimizer == 'sgd':\n","    opt = [optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd) for model in client_models]\n","elif args.optimizer == 'adam':\n","    opt = [optim.Adam(model.parameters(), lr=args.lr,  weight_decay=args.wd) for model in client_models]"]},{"cell_type":"markdown","source":["####Dataset split:"],"metadata":{"id":"Fkjqo3RYLvb_"}},{"cell_type":"code","source":["train_dataset, test_dataset, user_groups = get_dataset(args=args, unbalanced=unbalanced,)"],"metadata":{"id":"UuuyqdgXcLM2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xrNWvkQ_HPhy"},"source":["#Training"]},{"cell_type":"code","source":["# training\n","train_loss, train_accuracy = [], []\n","test_acc_list, test_loss_list = [], []\n","\n","for epoch in range(1, args.epochs+1):\n","    local_weights = []\n","    local_losses = []\n","    print(f'Epoch: {epoch} \\n')\n","    model.train()\n","    m = max(int(args.frac * args.num_users), 1) # num of users, at least 1\n","    idxs_users = np.random.choice(range(args.num_users), m, replace=False) \n","\n","    for idx in idxs_users: \n","        local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[idx],logger=logger, mu=mu) # consider in the local update the parameter mu\n","        w, loss = local_model.update_weights(model=copy.deepcopy(model), # pass the global model to the clients\n","                                             global_round=epoch)\n","        print('| Client : {} | Average Loss: {:.4f} '.format(idx, loss))\n","        local_weights.append(copy.deepcopy(w))\n","        local_losses.append(copy.deepcopy(loss))\n","\n","    # compute global weights (average of local weights)\n","    if unbalanced:\n","        global_weights = weighted_average_weights(local_weights, user_groups, idxs_users)\n","    else:\n","        global_weights = average_weights(local_weights)\n","\n","    # update weights of the global model\n","    model.load_state_dict(global_weights)\n","\n","    # compute average loss\n","    loss_avg = sum(local_losses) / len(local_losses)\n","    train_loss.append(loss_avg)\n","\n","    model.eval()\n","\n","    # calculate avg training accuracy over all users at every epoch\n","    list_acc, list_loss = [], []\n","    for client in range(args.num_users):\n","        local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[client],logger=logger, mu=mu)\n","        acc, loss = local_model.inference(model=model)\n","        list_acc.append(acc)\n","        list_loss.append(loss)\n","\n","    \n","    train_accuracy.append(sum(list_acc)/len(list_acc))\n","    print(f'\\nAverage training statistics (global epoch) : {epoch}')\n","    print(f'|---- Trainig Loss : {np.mean(np.array(train_loss))}')\n","    print('|---- Training Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n","    test_loss, test_acc = test(args, model,global_model, test_dataset)\n","    test_acc_list.append(test_acc)\n","    test_loss_list.append(test_loss)\n","    print('%d-th round' %epoch)\n","    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"],"metadata":{"id":"Fs2rXhjWMKEq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wEABlJEzHps3"},"source":["Storing the Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEyGlnuNHpEy"},"outputs":[],"source":["dict_ = {'train_acc' : train_accuracy, 'train_loss' : train_loss}\n","df = pd.DataFrame(dict_) \n","iid = ['iid' if args.iid else 'nonIID']\n","unb = ['unbalanced' if unbalanced and not args.iid else 'balanced' ]\n","bs = args.local_bs \n","filename = f\"fedPROX_{iid}_{unb}_{args.norm}{bs}_{args.epochs}_lr_{args.lr}_optimizer_{args.optimizer}\"\n","df = pd.DataFrame(dict_) \n","df.to_csv('/content/drive/MyDrive/FL2022/FedPROX/Results/'+filename+'.csv', encoding='utf-8')"]},{"cell_type":"markdown","metadata":{"id":"KMZgTc-EKEe-"},"source":["Showing the Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KboHhU1DHZnk"},"outputs":[],"source":["print(f' \\n Results after {args.epochs} global rounds of training:')\n","print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}